---
layout: post
title: "Linuxéƒ¨ç½²è”é‚¦å­¦ä¹ ï¼ˆä»¿çœŸï¼‰"
date: 2025-2-12 9:50 +0800
tags: [è”é‚¦å­¦ä¹ , ä»¿çœŸå®éªŒ]
toc:  true
excerpt:  "åœ¨linuxæ“ä½œç³»ç»Ÿè¿è¡Œè”é‚¦å­¦ä¹ ä»¿çœŸç¨‹åº"
---



## 1 ç¯å¢ƒ

æ“ä½œç³»ç»Ÿï¼šUbuntu 24.04

![](/img/blog11/1.png){: .align-center}

## 2 å®‰è£…docker

ç›¸å…³é…ç½®æ•™ç¨‹ï¼š

[ç³»ç»Ÿè¿ç»´|å¦‚ä½•åœ¨ Ubuntu ä¸Šå®‰è£… Docker](https://linux.cn/article-16531-1.html)

[Docker Hubä¸­æ‹‰å–é•œåƒæ—¶å‡ºç°è¶…æ—¶é—®é¢˜è¯¥å¦‚ä½•åšï¼Ÿ - å—¨ï¼Œé˜¿è‰¯ - åšå®¢å›­](https://www.cnblogs.com/fengting0913/p/12694452.html)

[GitHub - dongyubin/DockerHub: 2024å¹´12æœˆæ›´æ–°ï¼Œç›®å‰å›½å†…å¯ç”¨Dockeré•œåƒæºæ±‡æ€»ï¼ŒDockerHubå›½å†…é•œåƒåŠ é€Ÿåˆ—è¡¨ï¼ŒğŸš€DockerHubé•œåƒåŠ é€Ÿå™¨](https://github.com/dongyubin/DockerHub)

[ModuleNotFoundError: No module named â€˜distutilsâ€˜çš„è§£å†³åŠæ³•_modulenotfounderror: no module named 'distutils-CSDNåšå®¢](https://blog.csdn.net/weixin_59994137/article/details/137651135)

## 3 å»ºç«‹é…ç½®æ–‡ä»¶

### 3.1 dockerfile é…ç½®

dockerfile æ˜¯ä¸€ä¸ªæ–‡æœ¬æ–‡ä»¶ï¼Œå…¶ä¸­åŒ…å«äº†ä¸€ç³»åˆ—å‘½ä»¤ï¼Œç”¨äºå®šä¹‰æ„å»º Docker é•œåƒçš„æ­¥éª¤ã€‚ä½¿ç”¨ dockerfileå¯ä»¥ä¸ºè”é‚¦å­¦ä¹ éƒ¨ç½²ç¯å¢ƒåˆ›å»ºä¸€è‡´ä¸”å¯é‡å¤çš„ç¯å¢ƒé…ç½®ï¼Œç¡®ä¿æ¯ä¸ªèŠ‚ç‚¹éƒ½æœ‰ä¸€è‡´çš„å¼€å‘å’Œè¿è¡Œç¯å¢ƒã€‚

dockerfileæ–‡ä»¶é…ç½®å¦‚ä¸‹ï¼š

```
# ä½¿ç”¨å®˜æ–¹ Python 3.9 é•œåƒ
FROM python:3.9

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å®‰è£…ä¾èµ–
RUN pip install --upgrade pip
# ä½¿ç”¨æ¸…åæºï¼Œä¸‹è½½é€Ÿåº¦å¿«
RUN pip install -i https://pypi.tuna.tsinghua.edu.cn/simple tensorflow==2.18.0
RUN pip install  pandas==2.2.3 numpy==1.23.0 scikit-learn==1.6.0 matplotlib==3.9.3 plotly==5.24.1 flask==3.1.0


# å¤åˆ¶æœ¬åœ°ä»£ç åˆ°å®¹å™¨
# COPY federated_learning.py /app/federated_learning.py
COPY . /app

# é»˜è®¤å¯åŠ¨å®¢æˆ·ç«¯ï¼Œfederated_learning.pyæ˜¯è¿è¡Œè”é‚¦å­¦ä¹ çš„è„šæœ¬æ–‡ä»¶
CMD ["python", "federated_learning.py"]
```

### 3.2 docker compose éƒ¨ç½²æµç¨‹

docker composeç”¨äºå®šä¹‰å’Œè¿è¡Œå¤šä¸ªå®¹å™¨çš„åº”ç”¨ã€‚å¯¹äºè”é‚¦å­¦ä¹ ï¼Œé€šè¿‡docker composeå¯ä»¥æ–¹ä¾¿åœ°å®šä¹‰å¤šä¸ªå®¹å™¨åŠå…¶ä¹‹é—´çš„æœåŠ¡é“¾æ¥ï¼Œç®€åŒ–æ•´ä¸ªéƒ¨ç½²è¿‡ç¨‹ã€‚

docker-compose.ymlæ–‡ä»¶é…ç½®å¦‚ä¸‹

```yaml
version: '3'
services:
# è”é‚¦å­¦ä¹ çš„ä¸­å¿ƒæœåŠ¡å™¨
  server:
    build: .
    container_name: federated_server
    volumes:
      - ./federated_learning.py:/app/federated_learning.py  # å°†è®­ç»ƒè„šæœ¬æŒ‚è½½åˆ°æœåŠ¡å™¨å®¹å™¨ä¸­
    command: ["python", "federated_learning.py", "--mode", "server"]
    networks:
      - federated_network    # è®¾å®šå®¹å™¨é€šä¿¡ç½‘ç»œ
    ports:
      - "5000:5000"  # æœåŠ¡å™¨ç«¯å¼€æ”¾ç«¯å£ï¼Œå®¢æˆ·ç«¯é€šè¿‡è¿™ä¸ªç«¯å£è®¿é—®æœåŠ¡å™¨


  client1:
    build: .
    container_name: federated_client1
    volumes:
      - ./federated_learning.py:/app/federated_learning.py
      - /home/ysy/FL/FLdocker:/app
    command: ["python", "federated_learning.py", "--mode", "client", "--client_id", "1"]
    networks:
      - federated_network
    depends_on:          # æœåŠ¡ä¾èµ–ï¼Œä»£è¡¨è¯¥å®¹å™¨ä¼šåœ¨serverå¯åŠ¨åæ‰ç´§æ¥ç€å¯åŠ¨
      - server
    environment:
      - CLIENT_DATA_FILE=./Data/task_001.csv  # æŒ‡å®šå®¢æˆ·ç«¯1ä½¿ç”¨çš„CSVæ–‡ä»¶

  client2:
    build: .
    container_name: federated_client2
    volumes:
      - ./federated_learning.py:/app/federated_learning.py
    command: ["python", "federated_learning.py", "--mode", "client", "--client_id", "2"]
    networks:
      - federated_network
    depends_on:
      - client1
    environment:
      - CLIENT_DATA_FILE=./Data/task_005.csv

  client3:
    build: .
    container_name: federated_client3
    volumes:
      - ./federated_learning.py:/app/federated_learning.py
    command: ["python", "federated_learning.py", "--mode", "client", "--client_id", "3"]
    networks:
      - federated_network
    depends_on:
      - client2
    environment:
      - CLIENT_DATA_FILE=./Data/task_009.csv

  client4:
    build: .
    container_name: federated_client4
    volumes:
      - ./federated_learning.py:/app/federated_learning.py
    command: ["python", "federated_learning.py", "--mode", "client", "--client_id", "4"]
    networks:
      - federated_network
    depends_on:
      - client3
    environment:
      - CLIENT_DATA_FILE=./Data/task_010.csv

  client5:
    build: .
    container_name: federated_client5
    volumes:
      - ./federated_learning.py:/app/federated_learning.py
    command: ["python", "federated_learning.py", "--mode", "client", "--client_id", "5"]
    networks:
      - federated_network
    depends_on:
      - client4
    environment:
      - CLIENT_DATA_FILE=./Data/task_014.csv


networks:
  federated_network:
    driver: bridge       # æ‰€æœ‰å®¹å™¨éƒ½å°†é€šè¿‡è¿™ä¸ªç½‘ç»œè¿›è¡Œé€šä¿¡
```

### 3.3 é…ç½®è”é‚¦å­¦ä¹ ä»£ç 

æˆ‘ä»¬ç”¨è”é‚¦å­¦ä¹ è®­ç»ƒä¸€ä¸ªLSTMæ¨¡å‹ï¼Œç”¨ä»¥é¢„æµ‹ä»»åŠ¡æ‰§è¡Œè¿›åº¦

æ•°æ®é›†æ ¼å¼å¦‚ä¸‹ï¼š

![](/img/blog11/2.png){: .align-center}

è”é‚¦å­¦ä¹ çš„è®­ç»ƒæµç¨‹ä¸ºï¼š

- **åˆå§‹åŒ–å…¨å±€æ¨¡å‹**ï¼šæœåŠ¡å™¨åˆå§‹åŒ–å…¨å±€æ¨¡å‹æƒé‡ã€‚
- **å®¢æˆ·ç«¯è®­ç»ƒ**ï¼šå®¢æˆ·ç«¯ä»æœåŠ¡å™¨è·å–å…¨å±€æ¨¡å‹æƒé‡ï¼Œè¿›è¡Œæœ¬åœ°è®­ç»ƒï¼Œå¹¶å°†æ›´æ–°åçš„æƒé‡å‘é€åˆ°æœåŠ¡å™¨ã€‚
- **æƒé‡èšåˆ**ï¼šæœåŠ¡å™¨èšåˆå®¢æˆ·ç«¯ä¸Šä¼ çš„æƒé‡ï¼Œæ›´æ–°å…¨å±€æ¨¡å‹æƒé‡ã€‚
- **å…¨å±€æ¨¡å‹åˆ†å‘**ï¼šæœåŠ¡å™¨å°†æ›´æ–°åçš„å…¨å±€æ¨¡å‹æƒé‡åˆ†å‘ç»™å®¢æˆ·ç«¯ï¼Œå®¢æˆ·ç«¯ä½¿ç”¨æ–°çš„å…¨å±€æ¨¡å‹æƒé‡è¿›è¡Œä¸‹ä¸€è½®è®­ç»ƒã€‚

æˆ‘ä»¬ç¼–å†™çš„ä»£ç å¦‚ä¸‹ï¼š

```python
# federated_learning.py

import tensorflow as tf
import numpy as np
import pandas as pd
import argparse
import os
import json
import time
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from flask import Flask, request, jsonify
import requests  # ç”¨äºä¸æœåŠ¡å™¨é€šä¿¡
import warnings
warnings.filterwarnings('ignore', category=UserWarning, module='keras')

# åˆå§‹åŒ– Flask åº”ç”¨
app = Flask(__name__)
10
# è§£æå‘½ä»¤è¡Œå‚æ•°
parser = argparse.ArgumentParser()
parser.add_argument('--mode', type=str, required=True, choices=['server', 'client'], help="è¿è¡Œæ¨¡å¼ï¼šserver æˆ– client")
parser.add_argument('--client_id', type=int, help="å®¢æˆ·ç«¯IDï¼Œä»…åœ¨å®¢æˆ·ç«¯æ¨¡å¼ä¸‹éœ€è¦")
args = parser.parse_args()


# 1. å®šä¹‰LSTMæ¨¡å‹
def create_model():
    model = Sequential()
    model.add(LSTM(32,  input_shape=(None, 8), return_sequences=False))
    model.add(Dense(1))  # è¾“å‡ºä»»åŠ¡è¿›åº¦
    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])
    return model


# ä»æŒ‡å®šæ–‡ä»¶å¤¹åŠ è½½CSVæ–‡ä»¶
def load_data_from_file(file_path):
    df = pd.read_csv(file_path)
    
    # æ•°æ®é¢„å¤„ç†
    scaler = MinMaxScaler()
    scaled_data = scaler.fit_transform(
        df[['Progress', 'CPU_Frequency', 'Memory_Usage', 'Task_Type', 'Speed', 'Delay', 'Historical_Task_Count',
            'Historical_Task_Duration']]
    )
    
    # æ„å»ºLSTMçš„è¾“å…¥æ•°æ®æ ¼å¼ï¼šæ—¶é—´çª—å£
    def create_sequences(data, sequence_length):
        sequences = []
        labels = []
        for i in range(len(data) - sequence_length):
            sequences.append(data[i:i + sequence_length])
            labels.append(data[i + sequence_length, 0])  # ä»»åŠ¡è¿›åº¦ä½œä¸ºæ ‡ç­¾
        return np.array(sequences), np.array(labels)

    sequence_length = 10  # æ—¶é—´çª—å£å¤§å°
    X, y = create_sequences(scaled_data, sequence_length)
    return X, y


global_weights = None  # åˆå§‹åŒ–å…¨å±€æ¨¡å‹æƒé‡


# æœåŠ¡å™¨ç«¯ï¼šèšåˆå®¢æˆ·ç«¯æ¨¡å‹
def server_aggregation(client_weights):
    # è¿›è¡ŒåŠ æƒå¹³å‡ï¼ˆæ‰€æœ‰å®¢æˆ·ç«¯æƒé‡ç›¸ç­‰ï¼‰
    average_weights = [np.mean([client_weight[i] for client_weight in client_weights], axis=0)
                       for i in range(len(client_weights[0]))]
    return average_weights

# å®¢æˆ·ç«¯ï¼šè®­ç»ƒæ¨¡å‹å¹¶å°†æƒé‡è¿”å›ç»™æœåŠ¡å™¨
def client_training(client_id, file_path,global_weights):
    # åŠ è½½å®¢æˆ·ç«¯æ•°æ®å¹¶è¿›è¡Œè®­ç»ƒ
    X, y = load_data_from_file(file_path)
    
     # åˆ’åˆ†è®­ç»ƒé›†ä¸æµ‹è¯•é›†
    from sklearn.model_selection import train_test_split
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)
    
    # æ„å»ºæ¨¡å‹
    model = create_model()
    
    # å¦‚æœæœ‰å…¨å±€æƒé‡ï¼Œåˆ™è®¾ç½®æ¨¡å‹æƒé‡
    if global_weights is not None:
        global_weights = [np.array(weight) for weight in global_weights]
        model.set_weights(global_weights)
    
    history = model.fit(X_train, y_train, epochs=100, batch_size=32,verbose=0, validation_data=(X_test, y_test))
        # è¯„ä¼°æ¨¡å‹
    y_pred = model.predict(X_test)
    
    mse = mean_squared_error(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    
    print(f"Global model evaluation results: MSE={mse}, MAE={mae}, RMSE={rmse}")

    # è·å–è®­ç»ƒåçš„æƒé‡
    weights = model.get_weights()
   # å°†æƒé‡è½¬æ¢ä¸ºåˆ—è¡¨ï¼Œæ–¹ä¾¿ JSON åºåˆ—åŒ–
    weights_list = [weight.tolist() for weight in weights]
    return weights_list
 
# æœåŠ¡å™¨ç«¯ï¼šå­˜å‚¨å®¢æˆ·ç«¯çš„æƒé‡
client_weights = []

# å®¢æˆ·ç«¯ä¸Šä¼ æƒé‡çš„ API è·¯ç”±
@app.route('/update_weights', methods=['POST'])
def update_weights():
    updated_weights = request.json  # è·å–å®¢æˆ·ç«¯ä¸Šä¼ çš„æƒé‡
    client_weights.append(updated_weights)  # æ·»åŠ åˆ° client_weights åˆ—è¡¨
     # å¦‚æœæ”¶é›†åˆ°äº†æ‰€æœ‰å®¢æˆ·ç«¯çš„æƒé‡ï¼ˆæ¯”å¦‚å‡è®¾æœ‰5ä¸ªå®¢æˆ·ç«¯ï¼‰ï¼Œå°±è¿›è¡Œèšåˆ
    if len(client_weights) == 5:  # å‡è®¾æˆ‘ä»¬æœ‰5ä¸ªå®¢æˆ·ç«¯
        global global_weights  # åœ¨å‡½æ•°å†…éƒ¨ä¿®æ”¹å…¨å±€å˜é‡
        global_weights = server_aggregation(client_weights)
        if global_weights:
            app.logger.info("Global model updated.")
        else:
            print("No client weights received.")
            
        # æ¸…ç©º client_weightsï¼Œå‡†å¤‡ä¸‹ä¸€è½®çš„æƒé‡æ›´æ–°
        client_weights.clear()
    
    return jsonify({"status": "success"}), 200
     

# æœåŠ¡å™¨ç«¯ï¼šå‘æ”¾å…¨å±€æ¨¡å‹
@app.route('/get_global_model', methods=['GET'])
def get_global_model():
    if global_weights is None:
        return jsonify({"status": "error", "message": "No global model yet."}), 400
 
     # å°†æ¯ä¸ª NumPy æ•°ç»„è½¬æ¢ä¸ºåˆ—è¡¨
    global_weights_serializable = [weight.tolist() for weight in global_weights]
    
    # è¿”å›åºåˆ—åŒ–åçš„ global_weights
    return jsonify({"status": "success", "global_weights": global_weights_serializable}), 200
    

# å®¢æˆ·ç«¯ï¼šè·å–å…¨å±€æ¨¡å‹æƒé‡
def get_global_model():
    response = requests.get("http://server:5000/get_global_model")
    if response.status_code == 200:
        return response.json()['global_weights']
    else:
        return None


# å®¢æˆ·ç«¯ï¼šæ‰§è¡Œè”é‚¦å­¦ä¹ è¿­ä»£ç»†èŠ‚
def federated_learning_iteration(client_id, file_path):
    global_weights = get_global_model()  # è·å–å…¨å±€æ¨¡å‹æƒé‡
    
    if global_weights is None:
       print("No global model found, initializing model with random weights.")
       global_weights = initialize_global_model()  # åˆå§‹åŒ–å…¨å±€æ¨¡å‹çš„æƒé‡ï¼ˆä½ å¯ä»¥ä½¿ç”¨ä»»ä½•åˆå§‹åŒ–æ–¹æ³•ï¼‰
        
    if global_weights is not None:
        updated_weights = client_training(client_id, file_path, global_weights)
        print(f"Client {client_id} updated weights.")
        
        # å°†æ›´æ–°åçš„æƒé‡å‘é€åˆ°æœåŠ¡å™¨
        response = requests.post("http://server:5000/update_weights", json=updated_weights)
        print(f"Response from server: {response.status_code}")
        
             # å¦‚æœè¿”å›çŠ¶æ€æ˜¯ç­‰å¾…å…¶ä»–å®¢æˆ·ç«¯ï¼Œåˆ™å®¢æˆ·ç«¯å°†ç»§ç»­ç­‰å¾…
        if response.status_code == 200:
            print(f"Client {client_id} is waiting for other clients to finish this round.")
            while True:
                # æ£€æŸ¥æœåŠ¡å™¨æ˜¯å¦å·²æ›´æ–°å…¨å±€æ¨¡å‹ï¼Œä¸”æ‰€æœ‰å®¢æˆ·ç«¯å·²å®Œæˆ
                response = requests.get("http://server:5000/get_global_model")
                if response.status_code == 200:
                    new_global_weights = response.json().get('global_weights', None) 
                    if new_global_weights != global_weights:
                       print(f"Client {client_id} received updated global model. Proceeding to next round.")
                       break  # æ”¶åˆ°å…¨å±€æ¨¡å‹ï¼Œå¼€å§‹ä¸‹ä¸€è½®è®­ç»ƒ
                else:
                    print(f"Client {client_id} waiting for global model update.")
                    time.sleep(30)  # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡


# å®¢æˆ·ç«¯ï¼šæ‰§è¡Œå¤šä¸ªè®­ç»ƒå‘¨æœŸï¼ˆå¹¶è¡Œè¿›è¡Œï¼‰ï¼Œå®¢æˆ·ç«¯è¿­ä»£
def federated_learning_loop(file_path, rounds=10, num_clients=5):
    for round in range(rounds):
        print(f"Starting round {round + 1}")
        verbose=None
        # åŒæ—¶ä¸ºæ¯ä¸ªå®¢æˆ·ç«¯æ‰§è¡Œè®­ç»ƒ
        client_ids = range(num_clients)  # å‡è®¾æœ‰ `num_clients` ä¸ªå®¢æˆ·ç«¯
        
        # 1. æ‰€æœ‰å®¢æˆ·ç«¯å¹¶è¡Œæ‰§è¡Œè®­ç»ƒï¼Œå¹¶ä¸Šä¼ æƒé‡
        for client_id in client_ids:
            federated_learning_iteration(client_id, file_path)  # å®¢æˆ·ç«¯æ‰§è¡Œæœ¬åœ°è®­ç»ƒå¹¶ä¸Šä¼ æƒé‡
        
        print(f"Round {round + 1} completed.")


# åˆå§‹åŒ–å…¨å±€æ¨¡å‹
def initialize_global_model():
    # åˆ›å»ºä¸€ä¸ªæ–°çš„æ¨¡å‹å¹¶è¿”å›å…¶æƒé‡10
    model = create_model()  # ä½¿ç”¨ä¹‹å‰å®šä¹‰çš„ `create_model()` å‡½æ•°
    initial_weights = model.get_weights()  # è·å–æ¨¡å‹çš„åˆå§‹æƒé‡
    # å°†æƒé‡è½¬æ¢ä¸ºåˆ—è¡¨ä»¥ä¾¿äº JSON åºåˆ—åŒ–
    initial_weights_list = [weight.tolist() for weight in initial_weights]
    return initial_weights_list


# æœåŠ¡å™¨æ¨¡å¼ï¼šå¯åŠ¨ Flask æœåŠ¡å™¨å¹¶ç­‰å¾…å®¢æˆ·ç«¯ä¸Šä¼ æ›´æ–°
if __name__ == "__main__":
    if args.mode == 'server':
        print("Server mode: waiting for client updates...")
        app.run(host="0.0.0.0", port=5000)  # å¯åŠ¨ Flask æœåŠ¡å™¨ï¼Œç›‘å¬ 5000 ç«¯å£

    elif args.mode == 'client':
        print(f"Client {args.client_id} mode: training...")
        
        # ä»ç¯å¢ƒå˜é‡æˆ–å‘½ä»¤è¡Œå‚æ•°è·å–å®¢æˆ·ç«¯è¦ä½¿ç”¨çš„ CSV æ–‡ä»¶è·¯å¾„
        file_path = os.getenv('CLIENT_DATA_FILE', None)  # è¿™é‡Œæ ¹æ®å®é™…æƒ…å†µä¿®æ”¹æ–‡ä»¶è·¯å¾„
        
        if file_path:
            print(f"å®¢æˆ·ç«¯æ­£åœ¨è®­ç»ƒï¼š{file_path}")
            federated_learning_loop(file_path, rounds=10, num_clients=5)  # å‡è®¾æœ‰5ä¸ªå®¢æˆ·ç«¯
            print(f"Client {args.client_id} completed all rounds.")
           
        else:
            print("æœªæ‰¾åˆ°æŒ‡å®šçš„æ•°æ®æ–‡ä»¶è·¯å¾„ï¼")

```

ä¸Šè¿°ä»£ç æµç¨‹ï¼š

1. **æœåŠ¡å™¨å¯åŠ¨**ï¼šæœåŠ¡å™¨å¯åŠ¨ Flask åº”ç”¨ï¼Œç›‘å¬ç«¯å£ 5000ï¼Œç­‰å¾…å®¢æˆ·ç«¯ä¸Šä¼ æƒé‡ã€‚
2. **å®¢æˆ·ç«¯å¯åŠ¨**ï¼šå®¢æˆ·ç«¯ä»æœåŠ¡å™¨è·å–å…¨å±€æ¨¡å‹æƒé‡ï¼ŒåŠ è½½æœ¬åœ°æ•°æ®ï¼Œè¿›è¡Œè®­ç»ƒï¼Œå¹¶å°†æ›´æ–°åçš„æƒé‡å‘é€åˆ°æœåŠ¡å™¨ã€‚
3. **æƒé‡èšåˆ**ï¼šæœåŠ¡å™¨åœ¨æ”¶åˆ°æ‰€æœ‰å®¢æˆ·ç«¯çš„æƒé‡åï¼Œè¿›è¡Œèšåˆå¹¶æ›´æ–°å…¨å±€æ¨¡å‹ã€‚
4. **å…¨å±€æ¨¡å‹åˆ†å‘**ï¼šæœåŠ¡å™¨å°†æ›´æ–°åçš„å…¨å±€æ¨¡å‹æƒé‡åˆ†å‘ç»™å®¢æˆ·ç«¯ï¼Œå®¢æˆ·ç«¯ä½¿ç”¨æ–°çš„å…¨å±€æ¨¡å‹æƒé‡è¿›è¡Œä¸‹ä¸€è½®è®­ç»ƒã€‚
5. **é‡å¤è¿­ä»£**ï¼šé‡å¤ä¸Šè¿°è¿‡ç¨‹ï¼Œç›´åˆ°å®Œæˆæ‰€æœ‰è®­ç»ƒå‘¨æœŸã€‚



### 3.4 è¿è¡Œè”é‚¦å­¦ä¹ 

é¡¹ç›®ç›®å½•ç»“æ„ï¼š

```
project_directory/
â”‚
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ dockerfile
â”œâ”€â”€ federated_learning.py
â”œâ”€â”€ Data/
â”‚   â”œâ”€â”€ task_001.csv
â”‚   â”œâ”€â”€ task_005.csv
â”‚   â”œâ”€â”€ task_009.csv
â”‚   â”œâ”€â”€ task_010.csv
â”‚   â””â”€â”€ task_014.csv
â””â”€â”€ ...
```

é¦–å…ˆå¯åŠ¨å®¹å™¨ï¼š**systemctl start docker**

è¿›å…¥project_directoryç›®å½•ä¸‹ï¼š

æ‰§è¡Œå‘½ä»¤ï¼š**docker-compose up --build**

å¯åŠ¨ Docker Compose é¡¹ç›®ï¼Œé¦–æ¬¡è¿è¡Œè¯¥å‘½ä»¤ä¼šå…ˆä¸‹è½½ç¯å¢ƒä¾èµ–ï¼Œéœ€è¦ç­‰å¾…ä¸€å®šæ—¶é—´

ä¾èµ–å®‰è£…ç»“æŸä¹‹åï¼Œå¼€å§‹æ„å»ºè”é‚¦å­¦ä¹ çš„æœåŠ¡ç«¯å’Œå®¢æˆ·ç«¯ï¼š

![](/img/blog11/3.png){: .align-center}

è¡¨ç¤ºåˆ›å»ºæˆåŠŸã€‚

èµ·å§‹é˜¶æ®µï¼Œå„å®¢æˆ·ç«¯å…ˆä½¿ç”¨åˆå§‹å…¨å±€æ¨¡å‹å„è‡ªè¿›è¡Œè®­ç»ƒï¼š

![](/img/blog11/4.png){: .align-center}

å®¢æˆ·ç«¯ä½¿ç”¨æ•°æ®è¿›è¡Œæœ¬åœ°æ¨¡å‹è®­ç»ƒï¼Œå¹¶ä¸Šä¼ æ¨¡å‹æƒé‡åˆ°æœåŠ¡ç«¯ï¼š

ï¼ˆå¦‚æœæ­¤æ—¶å…¶å®ƒå®¢æˆ·ç«¯è¿˜æœªä¸Šä¼ æƒé‡ï¼Œåˆ™å·²ä¸Šä¼ æƒé‡çš„å®¢æˆ·ç«¯éœ€ç­‰å¾…ï¼‰

![](/img/blog11/5.png){: .align-center}

è·å–åˆ°å…¨å±€æ¨¡å‹æƒé‡åï¼Œè¿›å…¥ä¸‹ä¸€è½®è¿­ä»£ï¼š

![](/img/blog11/6.png){: .align-center}

æœåŠ¡å™¨ç«¯è·å–åˆ°æ‰€æœ‰å®¢æˆ·ç«¯ä¸Šä¼ çš„æƒé‡åï¼Œæ›´æ–°å…¨å±€æ¨¡å‹æƒé‡ï¼š

![](/img/blog11/7.png){: .align-center}

å„å®¢æˆ·ç«¯ç»“æŸè®­ç»ƒï¼š

![](/img/blog11/8.png){: .align-center}

ç»“æŸåï¼Œä½¿ç”¨Ctrl+Cé€€å‡ºæœåŠ¡ç«¯ï¼Œç„¶åæ‰§è¡Œå‘½ä»¤ï¼š

**docker-compose down**             é‡Šæ”¾æ‰€æœ‰å®¹å™¨èµ„æº

![](/img/blog11/9.png){: .align-center}

ä¸‹æ¬¡å†å¯åŠ¨è”é‚¦å­¦ä¹ ä»¿çœŸæ—¶ï¼Œå†æ¬¡æ‰§è¡Œ**docker-compose up --build**å³å¯



## 4.å±•æœ›

æœªæ¥è®¡åˆ’ï¼š

åœ¨ç¡¬ä»¶å¹³å°ä¸Šå®ç°è”é‚¦å­¦ä¹ 
